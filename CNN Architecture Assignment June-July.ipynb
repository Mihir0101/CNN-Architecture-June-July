{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c58954b-4ded-44e1-84f5-4f987c0eb685",
   "metadata": {},
   "source": [
    "# Understanding Pooling and Padding in CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83e0cb0-d5a2-4cf3-bd0f-ef01eda128b4",
   "metadata": {},
   "source": [
    "## 1.Describe the purpose and benefits of pooling in CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd24b884-8ef1-4195-b061-554888c64d18",
   "metadata": {},
   "source": [
    "* Purpose\n",
    "\n",
    "It helps in reducing the size of image.\n",
    "\n",
    "It reducing the size of image that forces the model to better generalize and it don't let the model to memorize the data. By doing this it solves the problem of overfitting.\n",
    "\n",
    "By distorting the input image it makes the model more robust to variations.\n",
    "\n",
    "* Benefits\n",
    "\n",
    "Pooling downsamples the image and because of that it reduces the number of neuron in a perticular layer.\n",
    "\n",
    "It helps in extracting dominant features.\n",
    "\n",
    "By reducing the overfitting it increases a genralization capability of the model and makes the model effective on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b811dd5d-265c-4dee-8298-a44395c39ddd",
   "metadata": {},
   "source": [
    "## 2.Explain the difference between min pooling and max pooling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77735ad-bc9c-4a63-a58b-1dd74e83ac50",
   "metadata": {},
   "source": [
    "* Key Differences\n",
    "\n",
    "Focus : Max pooling emphasizes the most significant features and min pooling emphasizes the least significant features.\n",
    "\n",
    "Impact : Max pooling makes the network more robust to variations by capturing strong signals and min pooling helps to capture low-contrast details the max pooling could overlook.\n",
    "\n",
    "Usage : Max pooling is more commonly used in standard CNN architectures, while min pooling is less common and is used in niche applications where weaker signals are important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93422cf-e62b-432e-ad98-036e7d74e01b",
   "metadata": {},
   "source": [
    "## 3.Discuss the concept of padding in CNN and its significance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc62f06-0c0e-4eba-9833-6b84d23a4556",
   "metadata": {},
   "source": [
    "* Definition\n",
    "\n",
    "Padding is process that adds extra pixels arround the inpute image or feature map. This is done before performing convolution operation.\n",
    "\n",
    "* Significance of Padding\n",
    "\n",
    "Preserves spatial dimensions : It is important in case where the size of the output needs to be the same as inpute.\n",
    "\n",
    "Retaines border information : Padding ensures that every pixel even the pixels at the border are also be included in convolution operations.\n",
    "\n",
    "Allow deeper networks : Padding allows the network to have more convolution layers without reducing the size of feature map too quickly.\n",
    "\n",
    "Avoids information loss : If we don't have padding so because of convolution layer we will loss our border information, by adding padding we can avoid the information loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665662df-8e24-4363-8714-161f3b06b361",
   "metadata": {},
   "source": [
    "## 4.Compare and contrast zero-padding and valid-padding in terms of their effects on the output feature map size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb3127f-5564-43fa-b1fb-272f48e04c87",
   "metadata": {},
   "source": [
    "Key Differences\n",
    "\n",
    "* Definition\n",
    "\n",
    "Zero-Padding : Adds extra pixels arround the inpute image, especially zeros.\n",
    "\n",
    "Valid-Padding : No extra pixels are added to inpute feature map.\n",
    "\n",
    "* Effect on Output Size\n",
    "\n",
    "Zero-Padding : Keeps the size of output image same as the inpute image.\n",
    "\n",
    "Valid-Padding : Reduces the size of output image as compare to input image.\n",
    "\n",
    "* Information Retention \n",
    "\n",
    "Zero-Padding : Retains the information from border pixels of feature map.\n",
    "\n",
    "Valid-Padding : Discards the information from the border and near the border pixels of feature map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1213fc8e-f5ef-47fa-85f4-9710338278e3",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7c8161-823e-477d-a492-7ebd6a151479",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f990c626-b65e-4f8b-8e51-a7b8a8230c63",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8c0f81-5495-4eaf-b9e6-2e337cacb237",
   "metadata": {},
   "source": [
    "# Exporing LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d09656d-3a7f-4959-bc10-543cb1c453d7",
   "metadata": {},
   "source": [
    "## 1.Provide a brief overview of LeNet-5 architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291182bb-b926-4cac-b703-09e120e63134",
   "metadata": {},
   "source": [
    "* Input Layer:\n",
    "\n",
    "Accepts a grayscale image of size 32×32pixels. The MNIST dataset images are originally 28×28, so they are zero-padded to match the input size of LeNet-5.\n",
    "\n",
    "* C1 - First Convolutional Layer:\n",
    "\n",
    "Applies 6 convolutional filters (kernels) of size 5×5 with a stride of 1, resulting in 6 feature maps of size 28×28(since no padding is used).\n",
    "\n",
    "Each filter detects different local patterns or features, such as edges or textures.\n",
    "\n",
    "Activation function: Sigmoid or tanh.\n",
    "\n",
    "* S2 - First Subsampling (Pooling) Layer:\n",
    "\n",
    "Averages the values in non-overlapping 2×2 windows using average pooling with a stride of 2, reducing the size of each feature map from 28×28 to 14×14.\n",
    "\n",
    "The number of feature maps remains the same (6).\n",
    "\n",
    "Activation function: Sigmoid or tanh.\n",
    "\n",
    "* C3 - Second Convolutional Layer:\n",
    "\n",
    "Applies 16 convolutional filters of size 5×5 to the pooled output.\n",
    "\n",
    "Different filters connect to different subsets of the input feature maps from the previous layer (not all 6 maps), resulting in 16 feature maps of size 10×10.\n",
    "\n",
    "Activation function: Sigmoid or tanh.\n",
    "\n",
    "* S4 - Second Subsampling (Pooling) Layer:\n",
    "\n",
    "Applies average pooling with a 2×2 window and a stride of 2, reducing the feature map size from 10×10 to 5×5.\n",
    "\n",
    "The number of feature maps remains the same (16).\n",
    "\n",
    "Activation function: Sigmoid or tanh.\n",
    "\n",
    "* C5 - Fully Connected Convolutional Layer:\n",
    "\n",
    "A fully connected layer with 120 units. Each of the 120 neurons is connected to all 400 (16 feature maps of size 5×5 inputs from the previous layer.\n",
    "\n",
    "This layer uses a set of learnable weights to combine features from the input maps.\n",
    "\n",
    "Activation function: Sigmoid or tanh.\n",
    "\n",
    "* F6 - Fully Connected Layer:\n",
    "\n",
    "A fully connected layer with 84 neurons, where each neuron is connected to all 120 inputs from the previous layer.\n",
    "\n",
    "Activation function: Sigmoid or tanh.\n",
    "\n",
    "* Output Layer:\n",
    "\n",
    "A fully connected layer with 10 neurons, corresponding to the 10 possible digit classes (0-9) for the MNIST dataset.\n",
    "\n",
    "Activation function: Softmax, which outputs a probability distribution over the 10 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8809af-0e47-404b-ab8e-132c23395454",
   "metadata": {},
   "source": [
    "## 2.Describe the key components of LeNet-5 and their respective purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b74004-03b0-4ea8-9bd7-7eb57739c3ee",
   "metadata": {},
   "source": [
    "* Input Layer: Takes a grayscale image of size 32×32 pixels as input, typically a zero-padded MNIST digit.\n",
    "\n",
    "* C1 - First Convolutional Layer: Applies 6 convolutional filters of size 5×5 to extract basic features (e.g., edges, textures). Produces 6 feature maps of size 28×28.\n",
    "\n",
    "* S2 - First Subsampling (Pooling) Layer: Performs average pooling with a 2×2 window, reducing each feature map size to 14×14 to decrease spatial dimensions and introduce translational invariance.\n",
    "\n",
    "* C3 - Second Convolutional Layer: Uses 16 convolutional filters of size 5×5 to learn more complex patterns from pooled features. Produces 16 feature maps of size 10×10.\n",
    "\n",
    "* S4 - Second Subsampling (Pooling) Layer: Further reduces feature map size to 5×5 through average pooling, maintaining the number of feature maps (16) while reducing computational load.\n",
    "\n",
    "* C5 - Fully Connected Convolutional Layer: A fully connected layer with 120 neurons to combine all previous features into a compact representation.\n",
    "\n",
    "* F6 - Fully Connected Layer: Has 84 neurons that learn complex combinations of features, bridging to the output.\n",
    "\n",
    "* Output Layer: A fully connected layer with 10 neurons representing 10 digit classes. Uses Softmax to output class probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69926218-75d0-4bde-8172-ee4cee268157",
   "metadata": {},
   "source": [
    "## 3.Discuss the advantages and limitations of LeNet-5 in the context of image classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6de4cd8-8f54-479e-a727-b4ef6c88213e",
   "metadata": {},
   "source": [
    "* Advantages\n",
    "\n",
    "LeNet-5 has a simple and straightforward architecture.\n",
    "\n",
    "The use of convolutional layers in LeNet-5 allows it to automatically learn hierarchical features from input images.\n",
    "\n",
    "By using pooling layer it achieves some level of translation invariance, which makes it more robust to restortion in image.\n",
    "\n",
    "LeNet-5 performs well on small, clean datasets like MNIST.\n",
    "\n",
    "* Limitations\n",
    "\n",
    "LeNet-5 is a relatively shallow network with only a few layers.\n",
    "\n",
    "The small kernel size (5x5) and shallow depth result in the network that can only capture small, localized patterns.\n",
    "\n",
    "LeNet-5 lacks modern regularization techniques like dropout, batch normalization, and data augmentation, making it prone to overfitting when trained on larger and more complex datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87393012-23dd-4197-afa4-97877a69bc9e",
   "metadata": {},
   "source": [
    "## 4.Implement LeNet-5 using a deep learning framework of your choice (e.g., TensorFlow, PyTorch) and train it on a publicly available dataset (e.g., MNIST). Evaluate its performance and provide insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af26ddd-a1b5-40db-9434-56cd6364db52",
   "metadata": {},
   "source": [
    "Jupyter notebook was not supporting the dataset, so I done the code in GoogleColab and below is the link of it :\n",
    "https://colab.research.google.com/drive/1rsSjgGThh4ncOXgCay49puaGJBgItFtp#scrollTo=gnAX_fG9NbVm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694e8e9a-2d5a-4fe4-b2a0-cba8651e0548",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0226390e-04fe-4dd9-89e1-16dd84801e1c",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0758e3bd-b4a0-4798-bfc8-8abd91ab279a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cf7ddd-bcb2-48e1-8d34-3136ce4ea1b9",
   "metadata": {},
   "source": [
    "# Analyzing the AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97b2642-e60b-4ea3-8312-677d70930573",
   "metadata": {},
   "source": [
    "## 1.Present an overview of the AlexNet architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15197846-da4d-426f-a523-a4159b803595",
   "metadata": {},
   "source": [
    "* Input Layer:\n",
    "\n",
    "Accepts RGB images of size 227×227×3 pixels. The original images from the ImageNet dataset are typically of size 256×256, which are randomly cropped and resized to 227×227 to fit the network.\n",
    "\n",
    "* First Convolutional Layer (Conv1):\n",
    "\n",
    "Applies 96 convolutional filters (kernels) of size 11×11×3 with a stride of 4 and padding of 0.\n",
    "\n",
    "Produces 96 feature maps of size 55×55.\n",
    "\n",
    "Followed by a ReLU activation function to introduce non-linearity.\n",
    "\n",
    "Utilizes Local Response Normalization (LRN) to normalize the activations, mimicking the lateral inhibition in real neurons.\n",
    "\n",
    "Uses max-pooling with a 3×3 window and a stride of 2 to reduce the size of each feature map to 27×27.\n",
    "\n",
    "* Second Convolutional Layer (Conv2):\n",
    "\n",
    "Applies 256 convolutional filters of size 5×5×48 with a stride of 1 and padding of 2.\n",
    "\n",
    "Produces 256 feature maps of size 27×27.\n",
    "\n",
    "Followed by a ReLU activation and Local Response Normalization (LRN).\n",
    "\n",
    "Uses max-pooling with a 3×3 window and a stride of 2, reducing the size of each feature map to 13×13.\n",
    "\n",
    "* Third Convolutional Layer (Conv3):\n",
    "\n",
    "Applies 384 convolutional filters of size 3×3×256 with a stride of 1 and padding of 1.\n",
    "\n",
    "Produces 384 feature maps of size 13×13.\n",
    "\n",
    "Followed by a ReLU activation function.\n",
    "\n",
    "* Fourth Convolutional Layer (Conv4):\n",
    "\n",
    "Applies 384 convolutional filters of size 3×3×192 with a stride of 1 and padding of 1.\n",
    "\n",
    "Produces 384 feature maps of size 13×13.\n",
    "\n",
    "Followed by a ReLU activation function.\n",
    "\n",
    "* Fifth Convolutional Layer (Conv5):\n",
    "\n",
    "Applies 256 convolutional filters of size 3×3×192 with a stride of 1 and padding of 1.\n",
    "\n",
    "Produces 256 feature maps of size 13×13.\n",
    "\n",
    "Followed by a ReLU activation function.\n",
    "\n",
    "Uses max-pooling with a 3×3 window and a stride of 2, reducing the size of each feature map to 6×6.\n",
    "\n",
    "* First Fully Connected Layer (FC6):\n",
    "\n",
    "Flattening the output from the last pooling layer (a total of 6×6×256=9216 units.\n",
    "\n",
    "Fully connected to 4096 neurons.\n",
    "\n",
    "Followed by a ReLU activation function.\n",
    "\n",
    "Uses dropout (with a probability of 0.5) to prevent overfitting.\n",
    "\n",
    "* Second Fully Connected Layer (FC7):\n",
    "\n",
    "Fully connected to 4096 neurons.\n",
    "\n",
    "Followed by a ReLU activation function.\n",
    "\n",
    "Uses dropout (with a probability of 0.5) to further prevent overfitting.\n",
    "\n",
    "* Output Layer (FC8):\n",
    "\n",
    "Fully connected to 1000 neurons, corresponding to the 1000 classes in the ImageNet dataset.\n",
    "\n",
    "Uses a Softmax activation function to output a probability distribution over the 1000 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eef6de-e325-4d4b-af4c-63d2b23d1294",
   "metadata": {},
   "source": [
    "## 2.Explain the architectural innovations introduced in AlexNet that contributed to its breakthrough performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63cefc3-1b47-47e7-a9ab-d0e5240ad35c",
   "metadata": {},
   "source": [
    "1. ReLU Activation Function :  AlexNet used the Rectified Linear Unit (ReLU) activation function instead of traditional activation functions like Sigmoid or Tanh.\n",
    "\n",
    "2. Dropout Regularization : AlexNet employed dropout in the fully connected layers. During each training iteration, dropout randomly \"drops out\" (sets to zero) a fraction (50%) of the neurons, effectively removing them from the network.\n",
    "\n",
    "3. Data Augmentation : AlexNet utilized data augmentation techniques to artificially expand the size of the training dataset. This included random cropping, horizontal flipping, and random changes in brightness, contrast, and color.\n",
    "\n",
    "4. Large Convolution Kernels and Strided Convolution : The first convolutional layer in AlexNet used relatively large convolutional kernels of size 11×11 with a stride of 4, followed by subsequent layers with smaller kernel sizes.\n",
    "\n",
    "5. Use of Multiple Convolution Layer : AlexNet was one of the first networks to use multiple stacked convolutional layers to progressively learn hierarchical features from low-level edges to high-level shapes and objects.\n",
    "\n",
    "6. Softmax Output Layer : The final layer of AlexNet uses a Softmax activation function to produce a probability distribution over the 1000 classes in the ImageNet dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c63c9f9-c69f-4f93-a9ab-7da10b89a599",
   "metadata": {},
   "source": [
    "## 3.Discuss the role of convolutional layers, pooling layers, and fully connected layers in AlexNet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4543fb-1d67-4894-a197-560ba26bff7f",
   "metadata": {},
   "source": [
    "* Convolutional Layers\n",
    "\n",
    "The convolution layer serves as a primary mechanism for feature learning in AlexNet.\n",
    "\n",
    "By stacking multiple convolution layers network can learn hierarchical representation, from low-level feature to more abstract patterns.\n",
    "\n",
    "It enhances the network's ability to observe more objects in image.\n",
    "\n",
    "* Pooling Layers\n",
    "\n",
    "By decreasing the dimensions of feature map it helps to decrease a number of parameters and computation cost.\n",
    "\n",
    "Max pooling introduces translation invariance, which allows network to recognize objects in different positions and orientations.\n",
    "\n",
    "It makes the network more robust to distortion in image.\n",
    "\n",
    "* Fully Connected Layers\n",
    "\n",
    "Fully connected layers synthesizes all learned features from convolution and pooling layer to make the final classification decision.\n",
    "\n",
    "This layers are capable of learning non-linear relationships, enhances the capability of network to classify diverse images.\n",
    "\n",
    "The ouput layers determines the final class of the inpute image by taking the class with highest probability from the softmax activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e71759-53bf-45fa-8fff-ddb90d624958",
   "metadata": {},
   "source": [
    "## 4.Implement AlexNet using a deep learning framework of your choice and evaluate its performance on a dataset of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dd026d-6cb8-46a6-a0b0-e7e1e457c7d8",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/drive/1GpLb3wCVu6v1DW-AVnUR3ArEyVjKnqJU#scrollTo=DnxTzA5uZk2d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
